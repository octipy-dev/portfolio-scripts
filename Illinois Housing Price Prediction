#!/usr/bin/env python3
"""
Illinois Housing Price Prediction

This script demonstrates a simple linear regression pipeline:
  1. Locate and load housing price data from CSV
  2. Clean missing values
  3. Select features and target variable
  4. Split into training and test sets
  5. Train a linear regression model
  6. Evaluate performance (MSE, R²)
  7. Plot actual vs. predicted prices

CSV discovery order when --csv-path is omitted:
  1. Current working directory
  2. Script's directory
  3. Script's "data/" subdirectory

Specify --csv-path to override.
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


def load_and_clean_data(csv_path: Path) -> pd.DataFrame:
    """
    Load the housing dataset and perform basic cleaning:
      - Read CSV into DataFrame
      - Display head, missing-value counts, and summary statistics
      - Drop any rows with missing values

    Parameters:
      csv_path (Path): Path to the CSV file

    Returns:
      pd.DataFrame: Cleaned DataFrame ready for modeling
    """
    try:
        data = pd.read_csv(csv_path)
    except Exception as e:
        raise FileNotFoundError(f"Failed to load CSV at {csv_path}: {e}")

    print(f"Loaded data from: {csv_path}\n")
    print("First 5 rows of data:")
    print(data.head(), "\n")

    print("Missing values in each column:")
    print(data.isnull().sum(), "\n")

    print("Summary statistics:")
    print(data.describe(), "\n")

    cleaned = data.dropna()
    dropped = len(data) - len(cleaned)
    print(f"Dropped {dropped} rows containing missing values.\n")
    return cleaned


def prepare_features(data: pd.DataFrame, feature_cols: list, target_col: str):
    """
    Extract feature matrix X and target vector y from the DataFrame.
    """
    return data[feature_cols], data[target_col]


def train_and_evaluate(X, y, test_size: float = 0.2, random_state: int = 42):
    """
    Split data, train a LinearRegression model, and evaluate it.
    """
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state
    )
    model = LinearRegression()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"Mean Squared Error (MSE): {mse:.2f}")
    print(f"R² Score: {r2:.3f}\n")

    return model, X_test, y_test, y_pred


def plot_predictions(y_test, y_pred):
    """
    Create a scatter plot comparing true vs. predicted prices.
    """
    plt.figure(figsize=(8, 6))
    plt.scatter(y_test, y_pred, alpha=0.7)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
    plt.xlabel('Actual Price')
    plt.ylabel('Predicted Price')
    plt.title('Actual vs. Predicted Housing Prices')
    plt.tight_layout()
    plt.show()


def parse_args():
    parser = argparse.ArgumentParser(
        description="Linear regression on Illinois housing prices."
    )
    parser.add_argument(
        "--csv-path", "-c",
        type=str,
        default=None,
        help="Path to the CSV file. If omitted, script searches cwd, script dir, then data/ subdir."
    )
    parser.add_argument(
        "--features", "-f",
        nargs='+',
        default=None,
        help="List of feature column names (e.g., bedrooms bathrooms sqft)."
    )
    parser.add_argument(
        "--target", "-t",
        type=str,
        default='price',
        help="Target column name (default: price)."
    )
    return parser.parse_args()


def discover_csv(provided_path: str) -> Path:
    """
    Discover CSV file path using provided CLI option or fallback locations.
    """
    if provided_path:
        return Path(provided_path)

    filename = 'illinois_housing_prices.csv'
    # Search order: cwd, script dir, script_dir/data/
    cwd_path = Path.cwd() / filename
    script_dir = Path(__file__).parent
    script_path = script_dir / filename
    data_subdir = script_dir / 'data' / filename

    for path in [cwd_path, script_path, data_subdir]:
        if path.exists():
            return path

    # None found
    return data_subdir  # final fallback for error message


def main():
    args = parse_args()
    csv_path = discover_csv(args.csv_path)

    if not csv_path.exists():
        print(f"Error: CSV file not found at {csv_path}")
        print("Place your dataset in one of these locations or provide --csv-path.")
        sys.exit(1)

    data = load_and_clean_data(csv_path)

    # Determine features
    if args.features:
        feature_cols = args.features
    else:
        feature_cols = [col for col in data.columns if col != args.target]
    target_col = args.target

    print(f"Using features: {feature_cols}")
    print(f"Target column: {target_col}\n")

    X, y = prepare_features(data, feature_cols, target_col)
    model, X_test, y_test, y_pred = train_and_evaluate(X, y)
    plot_predictions(y_test, y_pred)

    print("Model coefficients:")
    for feat, coef in zip(feature_cols, model.coef_):
        print(f"  {feat}: {coef:.3f}")
    print(f"Intercept: {model.intercept_:.3f}")


if __name__ == '__main__':
    main()
